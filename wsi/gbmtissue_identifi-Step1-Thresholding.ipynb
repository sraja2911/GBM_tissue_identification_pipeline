{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM Tissue Identification Pipeline using Scikit and Python packages\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import slide as slideprocess\n",
    "from slide import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import slide as slide\n",
    "from slide import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.join(\".\", \"/media/raj/Raj1_5/data\")\n",
    "# BASE_DIR = os.path.join(os.sep, \"Volumes\", \"BigData\", \"TUPAC\")\n",
    "TRAIN_PREFIX = \"TCGA-GBM-\"\n",
    "SRC_TRAIN_DIR = os.path.join(BASE_DIR, \"training_slides\")\n",
    "#SRC_TRAIN_DIR = os.path.join(BASE_DIR, \"training_image_data\")\n",
    "SRC_TRAIN_EXT = \"svs\"\n",
    "DEST_TRAIN_SUFFIX = \"\"  # Example: \"train-\"\n",
    "DEST_TRAIN_EXT = \"png\"\n",
    "SCALE_FACTOR = 32\n",
    "DEST_TRAIN_DIR = os.path.join(BASE_DIR, \"training_\" + DEST_TRAIN_EXT)\n",
    "THUMBNAIL_SIZE = 300\n",
    "THUMBNAIL_EXT = \"jpg\"\n",
    "\n",
    "DEST_TRAIN_THUMBNAIL_DIR = os.path.join(BASE_DIR, \"training_thumbnail_\" + THUMBNAIL_EXT)\n",
    "\n",
    "FILTER_SUFFIX = \"\"  # Example: \"filter-\"\n",
    "FILTER_RESULT_TEXT = \"filtered\"\n",
    "FILTER_DIR = os.path.join(BASE_DIR, \"filter_\" + DEST_TRAIN_EXT)\n",
    "FILTER_THUMBNAIL_DIR = os.path.join(BASE_DIR, \"filter_thumbnail_\" + THUMBNAIL_EXT)\n",
    "FILTER_PAGINATION_SIZE = 50\n",
    "FILTER_PAGINATE = True\n",
    "FILTER_HTML_DIR = BASE_DIR\n",
    "\n",
    "TILE_SUMMARY_DIR = os.path.join(BASE_DIR, \"tile_summary_\" + DEST_TRAIN_EXT)\n",
    "TILE_SUMMARY_ON_ORIGINAL_DIR = os.path.join(BASE_DIR, \"tile_summary_on_original_\" + DEST_TRAIN_EXT)\n",
    "TILE_SUMMARY_SUFFIX = \"tile_summary\"\n",
    "TILE_SUMMARY_THUMBNAIL_DIR = os.path.join(BASE_DIR, \"tile_summary_thumbnail_\" + THUMBNAIL_EXT)\n",
    "TILE_SUMMARY_ON_ORIGINAL_THUMBNAIL_DIR = os.path.join(BASE_DIR, \"tile_summary_on_original_thumbnail_\" + THUMBNAIL_EXT)\n",
    "TILE_SUMMARY_PAGINATION_SIZE = 50\n",
    "TILE_SUMMARY_PAGINATE = True\n",
    "TILE_SUMMARY_HTML_DIR = BASE_DIR\n",
    "\n",
    "TILE_DATA_DIR = os.path.join(BASE_DIR, \"tile_data\")\n",
    "TILE_DATA_SUFFIX = \"tile_data\"\n",
    "\n",
    "TOP_TILES_SUFFIX = \"top_tile_summary\"\n",
    "TOP_TILES_DIR = os.path.join(BASE_DIR, TOP_TILES_SUFFIX + \"_\" + DEST_TRAIN_EXT)\n",
    "TOP_TILES_THUMBNAIL_DIR = os.path.join(BASE_DIR, TOP_TILES_SUFFIX + \"_thumbnail_\" + THUMBNAIL_EXT)\n",
    "TOP_TILES_ON_ORIGINAL_DIR = os.path.join(BASE_DIR, TOP_TILES_SUFFIX + \"_on_original_\" + DEST_TRAIN_EXT)\n",
    "TOP_TILES_ON_ORIGINAL_THUMBNAIL_DIR = os.path.join(BASE_DIR,\n",
    "                                                   TOP_TILES_SUFFIX + \"_on_original_thumbnail_\" + THUMBNAIL_EXT)\n",
    "\n",
    "TILE_DIR = os.path.join(BASE_DIR, \"tiles_\" + DEST_TRAIN_EXT)\n",
    "TILE_SUFFIX = \"tile\"\n",
    "\n",
    "STATS_DIR = os.path.join(BASE_DIR, \"svs_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all the training WSI slides into jpg images, open the image using Openslide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Slide #4: /media/raj/Raj1_5/data/training_slides/TCGA-GBM-013-TCGA-02-0025-01Z-00-DX2.aa8923a0-2930-47f4-bbff-ceb080fafc9e.svs\n",
      "got openslide open: /media/raj/Raj1_5/data/training_slides/TCGA-GBM-013-TCGA-02-0025-01Z-00-DX2.aa8923a0-2930-47f4-bbff-ceb080fafc9e.svs\n",
      "Saving image to: /media/raj/Raj1_5/data/training_png/TCGA-GBM-004-32x-68003x40359-2125x1261.png\n"
     ]
    }
   ],
   "source": [
    "slideprocess.training_slide_to_image(4)\n",
    "img_path = slideprocess.get_training_image_path(4)\n",
    "img = slideprocess.open_image(img_path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = slideprocess.get_training_image_path(2)\n",
    "img = slideprocess.open_image(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### converts a PIL Image to a 3-dimensional NumPy array in RGB format; Util.py has pil_to_np_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB                  | Time: 0:00:00.153911  Type: uint8   Shape: (1336, 2684, 3)\n"
     ]
    }
   ],
   "source": [
    "rgb=util.pil_to_np_rgb(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.display_img(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.ndimage.morphology as sc_morph\n",
    "import skimage.color as sk_color\n",
    "import skimage.exposure as sk_exposure\n",
    "import skimage.feature as sk_feature\n",
    "import skimage.filters as sk_filters\n",
    "import skimage.future as sk_future\n",
    "import skimage.morphology as sk_morphology\n",
    "import skimage.segmentation as sk_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray                 | Time: 0:00:00.175453  Type: uint8   Shape: (1336, 2684)\n"
     ]
    }
   ],
   "source": [
    "grayscale = filter.filter_rgb_to_grayscale(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.display_img(grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WSI slide backgrounds are illuminated by white light, so \"pixel\" in the background of a grayscale image \n",
    "#### is usually close to or equal to 255, mathematically useful to have BG values close to 0, for thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB                  | Time: 0:00:00.143281  Type: uint8   Shape: (1336, 2684, 3)\n",
      "Gray                 | Time: 0:00:00.166655  Type: uint8   Shape: (1336, 2684)\n",
      "Complement           | Time: 0:00:00.001607  Type: uint8   Shape: (1336, 2684)\n"
     ]
    }
   ],
   "source": [
    "img_path = slideprocess.get_training_image_path(2)\n",
    "img = slideprocess.open_image(img_path)\n",
    "rgb = util.pil_to_np_rgb(img)\n",
    "grayscale = filter.filter_rgb_to_grayscale(rgb)\n",
    "complement = filter.filter_complement(grayscale)\n",
    "util.display_img(complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Contrast - intensities difference,Image with low contrast is dull and details are not clearly\n",
    "#### seen visually, high contrast is sharp and details can clearly be discerned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Aadaptive histogram equalization applies transformations to local regions.\n",
    "#### Adaptive equalization allows contrast to be enhanced to different extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB                  | Time: 0:00:00.143930  Type: uint8   Shape: (1336, 2684, 3)\n",
      "Gray                 | Time: 0:00:00.166935  Type: uint8   Shape: (1336, 2684)\n",
      "Adapt Equalization   | Time: 0:00:00.376487  Type: uint8   Shape: (1336, 2684)\n"
     ]
    }
   ],
   "source": [
    "img_path = slideprocess.get_training_image_path(2)\n",
    "img = slideprocess.open_image(img_path)\n",
    "rgb = util.pil_to_np_rgb(img)\n",
    "grayscale = filter.filter_rgb_to_grayscale(rgb)\n",
    "util.display_img(grayscale)\n",
    "adaptive_equ = filter.filter_adaptive_equalization(grayscale)\n",
    "util.display_img(adaptive_equ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### K-Means Segmentation with segments=3000\n",
    "#### scikit k-means clustering image segmentation is based on location and color, \n",
    "#### Allows regions of similarly colored pixels to be grouped together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB                  | Time: 0:00:00.142982  Type: uint8   Shape: (1336, 2684, 3)\n"
     ]
    }
   ],
   "source": [
    "### Original Image\n",
    "img_path = slideprocess.get_training_image_path(2)\n",
    "img = slideprocess.open_image(img_path)\n",
    "rgb = util.pil_to_np_rgb(img)\n",
    "util.display_img(rgb, bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Segmentation | Time: 0:00:51.199236  Type: uint8   Shape: (1336, 2684, 3)\n"
     ]
    }
   ],
   "source": [
    "#### k-means segmentation image\n",
    "kmeans_seg = filter.filter_kmeans_segmentation(rgb, n_segments=3000)\n",
    "util.display_img(kmeans_seg, bg=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray                 | Time: 0:00:00.166955  Type: uint8   Shape: (1336, 2684)\n",
      "Complement           | Time: 0:00:00.000912  Type: uint8   Shape: (1336, 2684)\n",
      "Otsu Threshold       | Time: 0:00:00.028042  Type: bool    Shape: (1336, 2684)\n",
      "Mask RGB             | Time: 0:00:00.013229  Type: uint8   Shape: (1336, 2684, 3)\n"
     ]
    }
   ],
   "source": [
    "#### otsu_masked image\n",
    "otsu_mask = util.mask_rgb(rgb, filter.filter_otsu_threshold(filter.filter_complement(filter.filter_rgb_to_grayscale(rgb)), output_type=\"bool\"))\n",
    "util.display_img(otsu_mask, bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Segmentation | Time: 0:00:50.314321  Type: uint8   Shape: (1336, 2684, 3)\n"
     ]
    }
   ],
   "source": [
    "####  \"K-Means Segmentation after Otsu Mask\",\n",
    "kmeans_seg_otsu = filter.filter_kmeans_segmentation(otsu_mask, n_segments=3000)\n",
    "util.display_img(kmeans_seg_otsu, bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Image morphology- Opening (Erosion followed by dilation applied) \n",
    "#### Erosion with disk structuring elements of radius 5 and radius 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB                  | Time: 0:00:00.161738  Type: uint8   Shape: (1336, 2684, 3)\n",
      "Filter Grays         | Time: 0:00:00.182189  Type: bool    Shape: (1336, 2684)\n"
     ]
    }
   ],
   "source": [
    "#### Binary image - Filter_grays function\n",
    "img_path = slideprocess.get_training_image_path(2)\n",
    "img = slideprocess.open_image(img_path)\n",
    "rgb = util.pil_to_np_rgb(img)\n",
    "no_grays = filter.filter_grays(rgb, output_type=\"bool\")\n",
    "util.display_img(no_grays, bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Erosion       | Time: 0:00:00.070834  Type: uint8   Shape: (1336, 2684)\n"
     ]
    }
   ],
   "source": [
    "#### Binary Erosion with radius = 5, erodes the edges on binary image\n",
    "bin_erosion_5 = filter.filter_binary_erosion(no_grays, disk_size=5)\n",
    "util.display_img(bin_erosion_5, bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Erosion       | Time: 0:00:00.195750  Type: uint8   Shape: (1336, 2684)\n"
     ]
    }
   ],
   "source": [
    "#### Binary Erosion with radius = 20, erodes the edges on binary image\n",
    "bin_erosion_20 = filter.filter_binary_erosion(no_grays, disk_size=20)\n",
    "util.display_img(bin_erosion_20, bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Apply_image_filters() function - Filters green channel, grays, red pen, green pen and blue pen masks\n",
    "#### and combines these into a single mask using boolean ANDs. Subsequently,small objects are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slide #2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'slide' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fe75a2941f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_filters_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/files/EmoryUni/Lab_SourceCode/GBM_TissueIdentification/deep-histopath/deephistopath/wsi/filter.py\u001b[0m in \u001b[0;36mapply_filters_to_image\u001b[0;34m(slide_num, save, display)\u001b[0m\n\u001b[1;32m   1094\u001b[0m   \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFILTER_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFILTER_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m   \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_training_image_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slide' is not defined"
     ]
    }
   ],
   "source": [
    "filter.apply_filters_to_image(2, display=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GBM Tissue Identification Pipeline",
   "language": "python",
   "name": "gbmpipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
